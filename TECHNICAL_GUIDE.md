# ğŸ¯ GuÃ­a TÃ©cnica - Hand Gesture PC Controller

## ğŸ“ Arquitectura del Sistema

### Componentes Principales

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Hand Controller                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   OpenCV     â”‚  â”‚  MediaPipe   â”‚  â”‚  PyAutoGUI   â”‚  â”‚
â”‚  â”‚ (Captura de  â”‚â†’ â”‚ (DetecciÃ³n   â”‚â†’ â”‚  (Control    â”‚  â”‚
â”‚  â”‚   Video)     â”‚  â”‚  de Manos)   â”‚  â”‚  del Mouse)  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de Datos

1. **Captura**: OpenCV captura frames de la webcam (640x480 @ 30fps)
2. **DetecciÃ³n**: MediaPipe procesa el frame y detecta 21 landmarks por mano
3. **AnÃ¡lisis**: Algoritmo personalizado analiza la posiciÃ³n de los dedos
4. **Reconocimiento**: Se identifica el gesto basado en el estado de los dedos
5. **AcciÃ³n**: PyAutoGUI ejecuta la acciÃ³n correspondiente en el sistema

## ğŸ§  Algoritmo de DetecciÃ³n de Gestos

### Landmarks de MediaPipe

MediaPipe detecta 21 puntos clave en cada mano:

```
        8   12  16  20
        |   |   |   |
    4   |   |   |   |
    |   7   11  15  19
    |   |   |   |   |
    3   6   10  14  18
    |   |   |   |   |
    2   5   9   13  17
    |   â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜
    1       PALM
    |
    0 (WRIST)
```

### DetecciÃ³n de Dedos Extendidos

```python
# Pulgar: ComparaciÃ³n horizontal (eje X)
thumb_extended = thumb_tip.x < thumb_ip.x

# Otros dedos: ComparaciÃ³n vertical (eje Y)
finger_extended = finger_tip.y < finger_pip.y
```

### Gestos Reconocidos

| Gesto | Dedos Extendidos | Estado | AcciÃ³n |
|-------|------------------|--------|--------|
| â˜ï¸ | `[?, T, F, F, F]` | MOVING | Mover cursor |
| âœŒï¸ | `[?, T, T, F, F]` | CLICKING | Click izquierdo |
| ğŸ–ï¸ | `[?, T, T, T, T]` | SCROLLING | Scroll vertical |
| ğŸ¤ | `[T, T, F, F, F]` | DRAGGING | Arrastrar y soltar |

*T = True (extendido), F = False (doblado), ? = cualquiera*

## âš™ï¸ ParÃ¡metros de ConfiguraciÃ³n

### MediaPipe Hands

```python
self.hands = self.mp_hands.Hands(
    static_image_mode=False,        # Modo video (no imagen estÃ¡tica)
    max_num_hands=1,                # Detectar solo 1 mano
    min_detection_confidence=0.7,   # Confianza mÃ­nima para detecciÃ³n
    min_tracking_confidence=0.7     # Confianza mÃ­nima para seguimiento
)
```

**Ajustes recomendados:**
- **Buena iluminaciÃ³n**: `min_detection_confidence=0.7`
- **Poca iluminaciÃ³n**: `min_detection_confidence=0.5`
- **Movimientos rÃ¡pidos**: `min_tracking_confidence=0.5`
- **PrecisiÃ³n mÃ¡xima**: ambos valores a `0.8` o mÃ¡s

### Suavizado del Cursor

```python
self.smoothing = 5  # Factor de suavizado (1-10)
smooth_x = prev_x + (x - prev_x) / smoothing
```

**Efectos del factor de suavizado:**
- `smoothing = 1`: Sin suavizado (movimiento directo pero nervioso)
- `smoothing = 5`: Balance entre precisiÃ³n y suavidad (recomendado)
- `smoothing = 10`: Muy suave pero con lag notable

### Cooldown de Clicks

```python
self.click_delay = 0.5  # segundos entre clicks
```

**Ajustes:**
- **Clicks rÃ¡pidos**: `0.3` segundos
- **Normal**: `0.5` segundos (recomendado)
- **Prevenir clicks accidentales**: `0.8` segundos

## ğŸ¨ PersonalizaciÃ³n Avanzada

### Agregar Nuevo Gesto

1. **Definir el patrÃ³n de dedos** en `detect_gesture()`:

```python
def detect_gesture(self, fingers):
    thumb, index, middle, ring, pinky = fingers
    
    # Nuevo gesto: Solo pulgar y meÃ±ique (rock sign ğŸ¤˜)
    if thumb and not index and not middle and not ring and pinky:
        return GestureState.CUSTOM_ACTION
```

2. **Agregar el estado** al enum:

```python
class GestureState(Enum):
    IDLE = 0
    MOVING = 1
    CLICKING = 2
    SCROLLING = 3
    DRAGGING = 4
    CUSTOM_ACTION = 5  # Nuevo estado
```

3. **Implementar la acciÃ³n** en el loop principal:

```python
elif gesture_state == GestureState.CUSTOM_ACTION:
    # Tu acciÃ³n personalizada
    pyautogui.hotkey('win', 'd')  # Mostrar escritorio
```

### Ejemplos de Acciones Personalizadas

```python
# Click derecho
pyautogui.rightClick()

# Doble click
pyautogui.doubleClick()

# Atajos de teclado
pyautogui.hotkey('ctrl', 'c')  # Copiar
pyautogui.hotkey('ctrl', 'v')  # Pegar
pyautogui.hotkey('alt', 'tab')  # Cambiar ventana

# Escribir texto
pyautogui.write('Hola Mundo', interval=0.1)

# Presionar teclas
pyautogui.press('enter')
pyautogui.press('space')
```

## ğŸ”§ OptimizaciÃ³n de Rendimiento

### Reducir Latencia

```python
# Reducir resoluciÃ³n de cÃ¡mara
self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320)
self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)

# Reducir complejidad de MediaPipe
self.hands = self.mp_hands.Hands(
    model_complexity=0,  # 0=ligero, 1=completo (default)
    max_num_hands=1
)
```

### Mejorar FPS

```python
# Procesar cada N frames
frame_count = 0
if frame_count % 2 == 0:  # Procesar 1 de cada 2 frames
    results = self.hands.process(rgb_frame)
frame_count += 1
```

## ğŸ› Debugging

### Visualizar Coordenadas

```python
# Mostrar coordenadas de landmarks
for idx, landmark in enumerate(hand_landmarks.landmark):
    print(f"Landmark {idx}: x={landmark.x:.3f}, y={landmark.y:.3f}")
```

### Logging de Gestos

```python
import logging

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# En detect_gesture()
logger.debug(f"Fingers: {fingers}, Gesture: {gesture_state}")
```

### Modo de Prueba (Sin Control del Mouse)

```python
# En __init__()
self.test_mode = True  # Activar modo prueba

# En move_cursor()
if not self.test_mode:
    pyautogui.moveTo(smooth_x, smooth_y)
else:
    print(f"TEST: Would move to ({smooth_x}, {smooth_y})")
```

## ğŸ“Š MÃ©tricas de Rendimiento

### Benchmarks TÃ­picos

| Hardware | FPS | Latencia | CPU |
|----------|-----|----------|-----|
| i5 8th Gen + Webcam 720p | 25-30 | ~50ms | 15-20% |
| i7 10th Gen + Webcam 1080p | 30+ | ~30ms | 10-15% |
| Laptop bÃ¡sico + Webcam 480p | 15-20 | ~80ms | 25-35% |

### Monitoreo en Tiempo Real

El overlay muestra:
- **FPS**: Frames por segundo procesados
- **State**: Estado actual del gesto
- **Cursor**: PosiciÃ³n del cursor en pantalla

## ğŸ”’ Seguridad y Limitaciones

### Fail-Safe Desactivado

```python
pyautogui.FAILSAFE = False
```

âš ï¸ **IMPORTANTE**: El fail-safe de PyAutoGUI estÃ¡ desactivado para permitir movimientos suaves. Normalmente, mover el mouse a la esquina superior izquierda detiene PyAutoGUI.

**Para reactivarlo** (recomendado durante desarrollo):
```python
pyautogui.FAILSAFE = True
```

### Limitaciones Conocidas

1. **IluminaciÃ³n**: Requiere buena iluminaciÃ³n para detecciÃ³n confiable
2. **Fondo**: Fondos complejos pueden afectar la detecciÃ³n
3. **Distancia**: Funciona mejor a 30-60cm de la cÃ¡mara
4. **Velocidad**: Movimientos muy rÃ¡pidos pueden perder tracking
5. **Una mano**: Solo detecta una mano a la vez

## ğŸš€ Mejoras Futuras

### Ideas para Implementar

- [ ] Soporte para dos manos
- [ ] Gestos dinÃ¡micos (movimientos en el tiempo)
- [ ] CalibraciÃ³n automÃ¡tica por usuario
- [ ] Perfiles de gestos personalizables
- [ ] IntegraciÃ³n con reconocimiento de voz
- [ ] Modo de entrenamiento para nuevos gestos
- [ ] Soporte para mÃºltiples monitores
- [ ] GrabaciÃ³n y reproducciÃ³n de macros gestuales

## ğŸ“š Referencias

- [MediaPipe Hands](https://google.github.io/mediapipe/solutions/hands.html)
- [OpenCV Documentation](https://docs.opencv.org/)
- [PyAutoGUI Documentation](https://pyautogui.readthedocs.io/)

---

**Â¿Preguntas o problemas?** Consulta el README.md principal o abre un issue.
